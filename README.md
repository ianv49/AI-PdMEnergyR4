# AI-EnergyForcastR4
AI-Driven Predictive Maintenance for Renewable Energy Assets 
# AI-Driven Predictive Maintenance for Renewable Energy Assets

This project develops a cross-platform application for predictive maintenance of renewable energy assets (wind turbines, solar panels, inverters, batteries). It uses IoT sensor data, external weather/solar APIs, and AI/ML models to forecast failures and optimize maintenance schedules.

---

## ðŸš€ Features
- Real-time sensor data ingestion (temperature, humidity, irradiance, wind speed).
- External API integration (OpenWeather, NASA POWER, Tomorrow.io).
- Local PostgreSQL + TimescaleDB storage for time-series data.
- Preprocessing scripts for normalization, cleaning, and interpolation.
- Ready for deployment on Raspberry Pi 4, but fully compatible with Mac and Windows laptops during development.

---

## ðŸ› ï¸ Development Setup

### 1. Clone Repository
```bash
AI-EnergyForcastR4/
â”‚
â”œâ”€â”€ db/                     # Database setup and connectors
â”‚   â”œâ”€â”€ db_connector.py     # Python script to handles DB connection
â”‚   â”œâ”€â”€ db_ingest.py        # Python script to ingestion script (imports connector)
â”‚   â”œâ”€â”€ test_connection.py  # Python script for quick connection test
â”‚   â””â”€â”€ schema.sql          # SQL table definitions
â”‚
â”œâ”€â”€ data/                 
â”‚   â”œâ”€â”€ sensor_logs.txt   # plain text log file 
â”‚   â””â”€â”€ sensor_data.csv   # CSV file 
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt      # List of Python dependencies
â”œâ”€â”€ README.md             # Documentation for setup and usage
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ ingestion.log         # todayâ€™s log)
â”‚   â””â”€â”€ ingestion.log.2026-01-20  #yesterdayâ€™s log, autoâ€‘created at midnight
â”‚
â”œâ”€â”€ sensors/              # Scripts for sensor data (real or simulated)
â”‚   â””â”€â”€ sensor_ingest.py  # First script: generate or simulate sensor readings
â”‚
â”œâ”€â”€ api_wrappers/         # External API modules
â”‚   â””â”€â”€ openweather.py    # First wrapper: fetch weather data
â”‚   â””â”€â”€ nasa_power.py     # Second wrapper: fetch solar/irradiance data
â”‚
â”‚
â”œâ”€â”€ preprocessing/        # Data cleaning scripts
â”‚   â””â”€â”€ preprocess.py     # First script: normalize and clean sensor logs
â”‚
â””â”€â”€ notebooks/            # Jupyter notebooks for demos
    â””â”€â”€ data_pipeline_demo.ipynb  # Step-by-step interactive demo

#### my notes
'''bash
Perfect ðŸŽ‰ â€” that package list shows your environment is now fully set up and healthy. Youâ€™ve got all the core libraries installed:
requests â†’ API calls and HTTP requests
pandas â†’ data handling and analysis
numpy â†’ numerical computations
psycopg2-binary â†’ PostgreSQL connector
scikit-learn â†’ classical machine learning models
torch â†’ PyTorch deep learning framework
matplotlib â†’ static plotting
plotly â†’ interactive charts
paho-mqtt â†’ IoT sensor communication
Plus all their dependencies (like scipy, joblib, threadpoolctl, etc.). This means youâ€™re ready to start coding your actual project.
PS D:\My Documents\tools\skul\bsu2024\bsu_mot512_thesis1\GithubVisualStudioCode\AI-EnergyForcastR4> python -m pip list
Package            Version
------------------ -----------
certifi            2026.1.4
charset-normalizer 3.4.4
contourpy          1.3.3
cycler             0.12.1
filelock           3.20.3
fonttools          4.61.1
fsspec             2026.1.0
idna               3.11
Jinja2             3.1.6
joblib             1.5.3
kiwisolver         1.4.9
MarkupSafe         3.0.3
matplotlib         3.10.8
mpmath             1.3.0
narwhals           2.15.0
networkx           3.6.1
numpy              2.4.1
packaging          25.0
paho-mqtt          2.1.0
pandas             2.3.3
pillow             12.1.0
pip                25.3
plotly             6.5.2
psycopg2-binary    2.9.11
pyparsing          3.3.1
python-dateutil    2.9.0.post0
pytz               2025.2
requests           2.32.5
scikit-learn       1.8.0
scipy              1.17.0
setuptools         80.9.0
six                1.17.0
sympy              1.14.0
threadpoolctl      3.6.0
torch              2.9.1
typing_extensions  4.15.0
tzdata             2025.3
urllib3            2.6.3

[always used for activating env; "venv\Scripts\activate.bat"]
[This starts PostgreSQL in the background, listening on port 5432.
Since you donâ€™t have admin rights, it wonâ€™t be a Windows service â€” youâ€™ll need to run this manually each time.
in <cmd> <"D:\My Documents\tools\postgresql\pgsql\bin\pg_ctl.exe" -D "D:\My Documents\tools\postgresql\pgsql\data" -l logfile start>]
[Stopping PostgreSQL. When youâ€™re done, stop the server cleanly, This shuts down PostgreSQL safely:
in cmd> <"D:\My Documents\tools\postgresql\pgsql\bin\pg_ctl.exe" -D "D:\My Documents\tools\postgresql\pgsql\data" stop>]
[Restarting PostgreSQL, If you want to restart:
in cmd> <"D:\My Documents\tools\postgresql\pgsql\bin\pg_ctl.exe" -D "D:\My Documents\tools\postgresql\pgsql\data" restart>]

...notes 260119;
Phase,Item,Status
Phase 1: Environment Setup,Install PostgreSQL portable binaries,Done
Phase 1: Environment Setup,Initialize database cluster (initdb),Done
Phase 1: Environment Setup,Start PostgreSQL manually (pg_ctl),Done
Phase 1: Environment Setup,Connect with psql,Done
Phase 2: Database Schema,Create energy_db database,Done
Phase 2: Database Schema,Define sensor_data table schema,Done
Phase 2: Database Schema,Verify schema with \d sensor_data,Done
Phase 3: Python Integration,Install psycopg2 driver,Done
Phase 3: Python Integration,Create db_ingest.py script,Done
Phase 3: Python Integration,Connect Python to PostgreSQL,Done
Phase 3: Python Integration,Insert test row via Python,Done
Phase 3: Python Integration,Fetch and display rows via Python,Done
Phase 4: Log Ingestion,Adapt script to read sensor_logs.txt,Done
Phase 4: Log Ingestion,Insert multiple rows from file,Done
Phase 4: Log Ingestion,Verify ingestion with query output,Done
Phase 5: Enhancements,Handle duplicate entries (unique timestamp + ON CONFLICT),Pending
Phase 5: Enhancements,Format timestamp output (seconds only),Done
Phase 5: Enhancements,Optional: pretty table output,Pending
Phase 6: Next Steps,Automate ingestion (batch file or cron job),Pending
Phase 6: Next Steps,Extend ingestion for CSV/real sensor streams,Pending
Phase 6: Next Steps,Dashboard/visualization integration,Pending

...notes 260120;
sql password = PdM
Phase,Item,Status
Phase 1: Environment Setup,Install PostgreSQL portable binaries,Done
Phase 1: Environment Setup,Initialize database cluster (initdb),Done
Phase 1: Environment Setup,Start PostgreSQL manually (pg_ctl),Done
Phase 1: Environment Setup,Connect with psql,Done
Phase 2: Database Schema,Create energy_db database,Done
Phase 2: Database Schema,Define sensor_data table schema,Done
Phase 2: Database Schema,Verify schema with \d sensor_data,Done
Phase 3: Python Integration,Install psycopg2 driver,Done
Phase 3: Python Integration,Create db_ingest.py script,Done
Phase 3: Python Integration,Connect Python to PostgreSQL,Done
Phase 3: Python Integration,Insert test row via Python,Done
Phase 3: Python Integration,Fetch and display rows via Python,Done
Phase 4: Log Ingestion,Adapt script to read sensor_logs.txt,Done
Phase 4: Log Ingestion,Insert multiple rows from file,Done
Phase 4: Log Ingestion,Verify ingestion with query output,Done
Phase 5: Enhancements,Handle duplicate entries (unique timestamp + ON CONFLICT),Done
Phase 5: Enhancements,Format timestamp output (seconds only),Done
Phase 5: Enhancements,Pretty table output (tabulate),Done
Phase 5: Enhancements,Row count before/after ingestion,Done
Phase 5: Enhancements,Skip header line in text ingestion,Done
Phase 5: Enhancements,Modularize connection into db_connector.py,Done
Phase 5: Enhancements,Add test_connection.py script,Done
Phase 5: Enhancements,Show top/bottom rows in test script,Done
Phase 6: Next Steps,Automate ingestion (batch file or cron job),Pending
Phase 6: Next Steps,Extend ingestion for CSV/real sensor streams,Pending
Phase 6: Next Steps,Dashboard/visualization integration,Pending
Phase 6: Next Steps,Add permanent log file output (logs/ingestion.log),Done
Phase 6: Next Steps,Daily log rotation (TimedRotatingFileHandler),Done
Phase 7: Visualization & Dashboard,Plot temperature vs timestamp chart,Pending
Phase 7: Visualization & Dashboard,Add multiple charts (humidity, irradiance, wind speed),Pending
Phase 7: Visualization & Dashboard,Build simple dashboard (Streamlit or Grafana),Pending
Phase 8: Real-Time Ingestion,Simulate sensor streams (append rows every minute),Pending
Phase 8: Real-Time Ingestion,Enable continuous ingestion pipeline,Pending
Phase 9: Predictive Analytics,Calculate averages/min/max/moving averages,Pending
Phase 9: Predictive Analytics,Train ML model for forecasting (scikit-learn),Pending
Phase 10: Deployment & Scaling,Containerize with Docker,Pending
Phase 10: Deployment & Scaling,Deploy to cloud (AWS/Azure/GCP),Pending
Phase 11: Web-Sensor Data Integration,Connect to OpenWeather API for local weather data,Pending
Phase 11: Web-Sensor Data Integration,Ingest NASA POWER API for solar irradiance and climate data,Pending
Phase 11: Web-Sensor Data Integration,Integrate PVOutput API for solar PV system performance,Pending
Phase 11: Web-Sensor Data Integration,Optional: Add other APIs (NOAA, Meteostat, etc.),Pending
Phase 11: Web-Sensor Data Integration,Normalize and store web-sensor data into sensor_data table,Pending
Phase 11: Web-Sensor Data Integration,Combine local sensor + web API data for richer analytics,Pending

